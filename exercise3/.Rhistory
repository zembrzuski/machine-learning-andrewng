z <- theta %*% t(x)
1/(1+exp(-z))
}
regularization <- function(lambda, m, theta) {
thetaSquaredWithoutThetaZero <- tail(theta, -1)^2
lambda / (2*m) * sum(thetaSquaredWithoutThetaZero)
}
cost <- function(x, y, theta, lambda) {
m <- nrow(x)
hipo <- hypothesis(theta, x)
vectorCostForEachPoint <- -y*log(hipo) - (1-y)*log(1-hipo)
regularization <- regularization(lambda, m, theta)
1/m * sum(vectorCostForEachPoint) + regularization
}
gradientDescent <- function(x, y, theta, alfa, nIter, lambda) {
m <- nrow(x)
cost <- rep(NA, nIter)
for(i in 1:nIter) {
cost[i] <- cost(x, y, theta, lambda)
# theta 0 derivative
summation <- (hypothesis(theta, x) - y) %*% x
theta0 <- head(summation[1,], 1)
# other thetas derivatives
parenthesis <- 1/m * tail(summation[1,], -1)
regularizationTerm <- lambda/m * tail(theta, -1)
thetaOthers <- parenthesis + regularizationTerm
theta <- theta - alfa * c(theta0, thetaOthers)
}
plot(cost)
theta
}
setwd('/home/nozes/github-machine-learning-coursera/exercise3')
digits = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- digits
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
y <- y$V1
as.numeric(digits[1,])
indexNumber <- 501
digit <- matrix(as.numeric(matrix(digits[indexNumber,], ncol = 20)), ncol=20)
rotate <- function(x) t(apply(x, 2, rev))
image(rotate(digit))
yResult <- function(y, number) {
sapply(y, function(x){
if (x == number) {
return(1)
} else {
return(0)
}
})
}
xxx <- as.matrix(sapply(x, as.numeric))
thetasDigitZero <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
thetasDigitZero
thetasDigitZero[1,]
thetasDigitZero
thetasDigitZero > 0.4
thetasDigitZero[1,]
thetasDigitZero[,1]
thetasDigitZero > 0.5
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
thetas1 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
thetas2 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
thetas3 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
rm(list = ls())
rm(list = ls())
mapFeature <- function(x) {
cbind(
rep(1, nrow(x)),
x[,2],
x[,3],
x[,2]^2,
x[,2]*x[,3],
x[,3]^2,
x[,2]^3,
x[,2]^2*x[,3],
x[,2]*x[,3]^2,
x[,3]^3,
x[,2]^4,
x[,2]^3*x[,3],
x[,2]^2*x[,3]^2,
x[,2]^1*x[,3]^3,
x[,3]^4,
x[,2]^5,
x[,2]^4*x[,3],
x[,2]^3*x[,3]^2,
x[,2]^2*x[,3]^3,
x[,2]^1*x[,3]^4,
x[,3]^5,
x[,2]^6,
x[,2]^5*x[,3]^1,
x[,2]^4*x[,3]^2,
x[,2]^3*x[,3]^3,
x[,2]^2*x[,3]^4,
x[,2]^1*x[,3]^5,
x[,3]^6
)
}
hypothesis <- function(theta, x) {
z <- theta %*% t(x)
1/(1+exp(-z))
}
regularization <- function(lambda, m, theta) {
thetaSquaredWithoutThetaZero <- tail(theta, -1)^2
lambda / (2*m) * sum(thetaSquaredWithoutThetaZero)
}
cost <- function(x, y, theta, lambda) {
m <- nrow(x)
hipo <- hypothesis(theta, x)
vectorCostForEachPoint <- -y*log(hipo) - (1-y)*log(1-hipo)
regularization <- regularization(lambda, m, theta)
1/m * sum(vectorCostForEachPoint) + regularization
}
gradientDescent <- function(x, y, theta, alfa, nIter, lambda) {
m <- nrow(x)
cost <- rep(NA, nIter)
for(i in 1:nIter) {
cost[i] <- cost(x, y, theta, lambda)
# theta 0 derivative
summation <- (hypothesis(theta, x) - y) %*% x
theta0 <- head(summation[1,], 1)
# other thetas derivatives
parenthesis <- 1/m * tail(summation[1,], -1)
regularizationTerm <- lambda/m * tail(theta, -1)
thetaOthers <- parenthesis + regularizationTerm
theta <- theta - alfa * c(theta0, thetaOthers)
}
plot(cost)
theta
}
setwd('/home/nozes/github-machine-learning-coursera/exercise3')
digits = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- digits
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
y <- y$V1
### visualizing data
as.numeric(digits[1,])
indexNumber <- 501
digit <- matrix(as.numeric(matrix(digits[indexNumber,], ncol = 20)), ncol=20)
rotate <- function(x) t(apply(x, 2, rev))
image(rotate(digit))
### training logistic regression for digit 0
yResult <- function(y, number) {
sapply(y, function(x){
if (x == number) {
return(1)
} else {
return(0)
}
})
}
xxx <- as.matrix(sapply(x, as.numeric))
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 1)
thetas1 <- gradientDescent(xxx, yResult(y, 1), rep(0, 400), 0.05, 300, 1)
thetas2 <- gradientDescent(xxx, yResult(y, 2), rep(0, 400), 0.05, 300, 1)
thetas3 <- gradientDescent(xxx, yResult(y, 3), rep(0, 400), 0.05, 300, 1)
thetas4 <- gradientDescent(xxx, yResult(y, 4), rep(0, 400), 0.05, 300, 1)
thetas5 <- gradientDescent(xxx, yResult(y, 5), rep(0, 400), 0.05, 300, 1)
thetas6 <- gradientDescent(xxx, yResult(y, 6), rep(0, 400), 0.05, 300, 1)
thetas7 <- gradientDescent(xxx, yResult(y, 7), rep(0, 400), 0.05, 300, 1)
thetas8 <- gradientDescent(xxx, yResult(y, 8), rep(0, 400), 0.05, 300, 1)
thetas9 <- gradientDescent(xxx, yResult(y, 9), rep(0, 400), 0.05, 300, 1)
print('acabou')
thetasMatrix <- rbind(thetas0, thetas1, thetas, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
thetasMatrix <- rbind(thetas0, thetas1, thetas2, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
hypothesis <- function(theta, x) {
z <- t(theta) %*% x
1/(1+exp(-z))
}
xxx
xxx[1,]
hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[1:2,])[1,] > 0.5
hypothesis <- function(theta, x) {
z <- theta %*% t(x)
1/(1+exp(-z))
}
hypothesis(thetasMatrix, xxx[1:2,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[4999:5000,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[1:2,])[1,] > 0.5
hypothesis <- function(theta, x) {
z <- x %*% t(theta)
1/(1+exp(-z))
}
hypothesis(thetasMatrix, xxx[1:2,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[5000,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[4000,])[1,] > 0.5
hypothesis(thetasMatrix, xxx[4000:4001,])[1,] > 0.5
for(i in 1:5000) {
print(y[i])
print(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5)
}
for(i in 1:5000) {
paste(print(y[i]), print(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5))
}
hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5
y[1]
hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5
(hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5  )[1]
(hypothesis(thetasMatrix, xxx[1,])[1,] > 0.5  )[1] == TRUE
y[800]
y[3000]
yy = read.csv2('input/yy.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
yy <- y$V1
yy = read.csv2('input/yy.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
yy
yy <- y$V1
head(yy)
y$V1
yy <- y[1,
yy <- y[1,]
yy <- y[1,]
yy <- y[1,]
yy
yy <- y[,1]
yy <- yy$V1
yy
i <- 1
yy[i]
i <- 500
yy[i]
i <- 501
yy[i]
i <- 5000
yy[i]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[1]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[0]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[1]
i <- 5000
yy[i]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[1]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[10]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
i <- 0
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )
i <- 1
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
i <- 2
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
i <- 500
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
i <- 501
(hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
for(i in 1:5000) {
result <- (hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
acertou <- 0
errou <- 0
if (result == TRUE) {
acertou <- acertou+1
} else {
errou <- errou+1
}
print(acertou)
print(errou)
}
acertou <- 0
errou <- 0
for(i in 1:5000) {
result <- (hypothesis(thetasMatrix, xxx[i,])[1,] > 0.5  )[yy[i]+1]
if (result == TRUE) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
for(i in 1:5000) {
result <- (hypothesis(thetasMatrix, xxx[i,])[1,] > 0.3  )[yy[i]+1]
if (result == TRUE) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
hypothesis(thetasMatrix, xxx[1,])[1,]
res <- hypothesis(thetasMatrix, xxx[1,])[1,]
max(res)
which(max(res))
which.max(res)
res <- hypothesis(thetasMatrix, xxx[5000,])[1,]
which.max(res)
res <- hypothesis(thetasMatrix, xxx[5000,])[1,]
which.max(res)
res <- hypothesis(thetasMatrix, xxx[3000,])[1,]
which.max(res)
yy[3000]
acertou <- 0
errou <- 0
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (res == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
i <- 0
expected <- yy[i]+1
expected
yy[i]
yy
yy[i]
i <- 1
yy[i]
expected <- yy[i]+1
expected
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
res
acertou <- 0
errou <- 0
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (which.max(res) == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
4265+735
4265/(4265+735)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise3')
digits = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- digits
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
y <- y$V1
yy = read.csv2('input/yy.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
yy <- yy$V1
### visualizing data
as.numeric(digits[1,])
indexNumber <- 501
digit <- matrix(as.numeric(matrix(digits[indexNumber,], ncol = 20)), ncol=20)
rotate <- function(x) t(apply(x, 2, rev))
image(rotate(digit))
### training logistic regression for digit 0
yResult <- function(y, number) {
sapply(y, function(x){
if (x == number) {
return(1)
} else {
return(0)
}
})
}
xxx <- as.matrix(sapply(x, as.numeric))
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 500, 1)
hypothesis <- function(theta, x) {
#z <- x %*% t(theta)
z <- theta %*% t(x)
1/(1+exp(-z))
}
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 500, 1)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
### preparing data
rm(list = ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise3')
digits = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- digits
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
y <- y$V1
yy = read.csv2('input/yy.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
yy <- yy$V1
### visualizing data
as.numeric(digits[1,])
indexNumber <- 501
digit <- matrix(as.numeric(matrix(digits[indexNumber,], ncol = 20)), ncol=20)
rotate <- function(x) t(apply(x, 2, rev))
image(rotate(digit))
### training logistic regression for digit 0
yResult <- function(y, number) {
sapply(y, function(x){
if (x == number) {
return(1)
} else {
return(0)
}
})
}
xxx <- as.matrix(sapply(x, as.numeric))
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 500, 1)
thetas1 <- gradientDescent(xxx, yResult(y, 1), rep(0, 400), 0.05, 500, 1)
thetas2 <- gradientDescent(xxx, yResult(y, 2), rep(0, 400), 0.05, 500, 1)
thetas3 <- gradientDescent(xxx, yResult(y, 3), rep(0, 400), 0.05, 500, 1)
thetas4 <- gradientDescent(xxx, yResult(y, 4), rep(0, 400), 0.05, 500, 1)
thetas5 <- gradientDescent(xxx, yResult(y, 5), rep(0, 400), 0.05, 500, 1)
thetas6 <- gradientDescent(xxx, yResult(y, 6), rep(0, 400), 0.05, 500, 1)
thetas7 <- gradientDescent(xxx, yResult(y, 7), rep(0, 400), 0.05, 500, 1)
thetas8 <- gradientDescent(xxx, yResult(y, 8), rep(0, 400), 0.05, 500, 1)
thetas9 <- gradientDescent(xxx, yResult(y, 9), rep(0, 400), 0.05, 500, 1)
print('acabou')
thetasMatrix <- rbind(thetas0, thetas1, thetas2, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
acertou <- 0
errou <- 0
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (which.max(res) == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
hypothesis <- function(theta, x) {
z <- x %*% t(theta)
#z <- theta %*% t(x)
1/(1+exp(-z))
}
print('acabou')
thetasMatrix <- rbind(thetas0, thetas1, thetas2, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
acertou <- 0
errou <- 0
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (which.max(res) == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
4329/5000
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
hypothesis <- function(theta, x) {
#z <- x %*% t(theta)
z <- theta %*% t(x)
1/(1+exp(-z))
}
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 100, 0)
thetas1 <- gradientDescent(xxx, yResult(y, 1), rep(0, 400), 0.05, 100, 0)
thetas2 <- gradientDescent(xxx, yResult(y, 2), rep(0, 400), 0.05, 100, 0)
thetas3 <- gradientDescent(xxx, yResult(y, 3), rep(0, 400), 0.05, 100, 0)
thetas4 <- gradientDescent(xxx, yResult(y, 4), rep(0, 400), 0.05, 100, 0)
thetas5 <- gradientDescent(xxx, yResult(y, 5), rep(0, 400), 0.05, 100, 0)
thetas6 <- gradientDescent(xxx, yResult(y, 6), rep(0, 400), 0.05, 100, 0)
thetas7 <- gradientDescent(xxx, yResult(y, 7), rep(0, 400), 0.05, 100, 0)
thetas8 <- gradientDescent(xxx, yResult(y, 8), rep(0, 400), 0.05, 100, 0)
thetas9 <- gradientDescent(xxx, yResult(y, 9), rep(0, 400), 0.05, 100, 0)
print('acabou')
thetasMatrix <- rbind(thetas0, thetas1, thetas2, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
acertou <- 0
errou <- 0
hypothesis <- function(theta, x) {
z <- x %*% t(theta)
#z <- theta %*% t(x)
1/(1+exp(-z))
}
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (which.max(res) == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
hypothesis <- function(theta, x) {
#z <- x %*% t(theta)
z <- theta %*% t(x)
1/(1+exp(-z))
}
thetas0 <- gradientDescent(xxx, yResult(y, 10), rep(0, 400), 0.05, 300, 0)
thetas1 <- gradientDescent(xxx, yResult(y, 1), rep(0, 400), 0.05, 300, 0)
thetas2 <- gradientDescent(xxx, yResult(y, 2), rep(0, 400), 0.05, 300, 0)
thetas3 <- gradientDescent(xxx, yResult(y, 3), rep(0, 400), 0.05, 300, 0)
thetas4 <- gradientDescent(xxx, yResult(y, 4), rep(0, 400), 0.05, 300, 0)
thetas5 <- gradientDescent(xxx, yResult(y, 5), rep(0, 400), 0.05, 300, 0)
thetas6 <- gradientDescent(xxx, yResult(y, 6), rep(0, 400), 0.05, 300, 0)
thetas7 <- gradientDescent(xxx, yResult(y, 7), rep(0, 400), 0.05, 300, 0)
thetas8 <- gradientDescent(xxx, yResult(y, 8), rep(0, 400), 0.05, 300, 0)
thetas9 <- gradientDescent(xxx, yResult(y, 9), rep(0, 400), 0.05, 300, 0)
print('acabou')
hypothesis <- function(theta, x) {
z <- x %*% t(theta)
#z <- theta %*% t(x)
1/(1+exp(-z))
}
thetasMatrix <- rbind(thetas0, thetas1, thetas2, thetas3, thetas4, thetas5, thetas6, thetas7, thetas8, thetas9)
acertou <- 0
errou <- 0
for(i in 1:5000) {
expected <- yy[i]+1
res <- hypothesis(thetasMatrix, xxx[i,])[1,]
if (which.max(res) == expected) {
acertou <- acertou+1
} else {
errou <- errou+1
}
}
print(acertou)
print(errou)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
