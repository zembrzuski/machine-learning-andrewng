myData <- cbind(input$V1, input$V2)
myData <- cbind(input$V1, input$V2))
myData <- cbind(input$V1, input$V2))
myData <- cbind(input$V1, input$V2)
myData
input$V1
input$V1
input$V1
rm(list = ls())
input <- read.csv2('/home/nozes/Desktop/ml2/ex2/ex2data1.txt' , header = FALSE, sep = ',', stringsAsFactors = FALSE)
colors <- sapply(input$V3, function(x){
if (x == 0) {
return("red")
} else {
return("blue")
}
})
input$V3 <- colors
input
input$V1
as.numeric(input$V1)
myData <- cbind(as.numeric(input$V1), as.numeric(input$V2))
myData
myMatrix <- cbind(rep(1, length(nrow(myData))), myData)
yVector <- input$V3
myMatrix
yVector
input <- read.csv2('/home/nozes/Desktop/ml2/ex2/ex2data1.txt' , header = FALSE, sep = ',', stringsAsFactors = FALSE)
myMatrix
yVector <- input$V3
myMatrix
yVector
costs <- gradient(c(0.5, 0.5, 0.5), 0.01, 10000, myMatrix, yVector)
source('~/cousera-ml/logistic-regression/logisticRegression.R')
costs <- gradient(c(0.5, 0.5, 0.5), 0.01, 10000, myMatrix, yVector)
costs
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.01, 10000, myMatrix, yVector)
costs <- gradient(c(0.5, 0.5, 0.5), 0.0.1, 10000, myMatrix, yVector)
costs <- gradient(c(0.5, 0.5, 0.5), 0.001, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.0001, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00005, 10000, myMatrix, yVector)
costs <- gradient(c(0.5, 0.5, 0.5), 0.0001, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00009, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00008, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00007, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00006, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00005, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00002, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 10000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 50000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.000015, 20000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 50000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 100000, myMatrix, yVector)
plot(costs)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 200000, myMatrix, yVector)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 200000, myMatrix, yVector)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 100000, myMatrix, yVector)
plot(costs)
predicting <- hypothesis(c(-4.578479, 0.04352324, 0.03635591), myMatrix) >= 0.5
predicting <- hypothesis(c(-4.578479, 0.04352324, 0.03635591), myMatrix) >= 0.5
rbind(predicting, yVector)
cbind(predicting, yVector)
predicting <- hypothesis(c(-4.578479, 0.04352324, 0.03635591), myMatrix) >= 0.5
rbind(predicting, yVector)
plot(input$V1, input$V2, col = input$V3, pch=16)
input$V3 <- colors
plot(input$V1, input$V2, col = input$V3, pch=16)
hypothesis(c(-4.578479, 0.04352324, 0.03635591), c(1,70,30)) >= 0.5
hypothesis(c(-4.578479, 0.04352324, 0.03635591), cbind((c1,70,30))) >= 0.5
hypothesis(c(-4.578479, 0.04352324, 0.03635591), cbind(c(1,70,30))) >= 0.5
hypothesis(c(-4.578479, 0.04352324, 0.03635591), c(1,30,40)) >= 0.5
cbind(c(1,30,40))
rbind(c(1,30,40))
as.matrix(rbind(c(1,30,40)))
rrr <- as.matrix(rbind(c(1,30,40)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr) >= 0.5
rrr <- as.matrix(rbind(c(1,100,80)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr) >= 0.5
rrr <- as.matrix(rbind(c(1,70,50)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr) >= 0.5
rrr <- as.matrix(rbind(c(1,70,40)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr) >= 0.5
rrr <- as.matrix(rbind(c(1,70,40)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr)
rrr <- as.matrix(rbind(c(1,70,45)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr)
rrr <- as.matrix(rbind(c(1,45,485)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr)
rrr <- as.matrix(rbind(c(1,45,85)))
hypothesis(c(-4.578479, 0.04352324, 0.03635591), rrr)
costs <- gradient(c(0.5, 0.5, 0.5), 0.00001, 150000, myMatrix, yVector)
rrr <- as.matrix(rbind(c(1,45,85)))
hypothesis(c(-6.099932, 0.05508169, 0.04833282), rrr)
input <- read.csv2('/home/nozes/Desktop/ml2/ex2/ex2data2.txt' , header = FALSE, sep = ',', stringsAsFactors = FALSE)
input
colors <- sapply(input$V3, function(x){
if (x == 0) {
return("red")
} else {
return("blue")
}
})
input$V3 <- colors
plot(input$V1, input$V2, col = input$V3, pch=16)
rm(list = ls())
source("http://bit.ly/dasi_inference")
rm(list = ls())
source("http://bit.ly/dasi_inference")
load(url("http://www.openintro.org/stat/data/atheism.RData"))
head(atheism)
subset(atheism, nationality == 'United States')
head(atheism)
subset(atheism, nationality == 'United States' & year == '2012')
us12 <- subset(atheism, nationality == 'United States' & year == '2012')
head(us12)
us12$response
subset(us12, response == 'atheist')
nrow(subset(us12, response == 'atheist'))
nrow(us12)
50/1002
pnorm(0.975)
sqrt(0.0499002*(1-0.0499002)/1002)
pnorm(0.975)
pnorm(0.975) * sqrt(0.0499002*(1-0.0499002)/1002)
inference(us12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
(0.0634 - 0.0364)/2
p <- 50/1002
n <- nrow(us12)
se <- sqrt( p*(1-p)/n )
se
qnorm(0.975)
qnorm(0.975) * se
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2*sqrt(p*(1 - p)/n)
plot(me ~ p)
subset(atheism, nationality == 'Spain' & year == '2012')
load(url("http://www.openintro.org/stat/data/atheism.RData"))
subset(atheism, nationality == 'Spain' & year == '2012')
head(subset(atheism, nationality == 'Spain' & year == '2012'))
subset(atheism, nationality == 'Spain' & year == '2012')$year
subset(atheism, nationality == 'Spain')$year
spain12 <- subset(atheism, nationality == 'Spain' & year == '2012')
spain05 <- subset(atheism, nationality == 'Spain' & year == '2005')
spain12
spain05
head(spain12)
subset(spain12, response == 'atheist')
nrow(subset(spain12, response == 'atheist'))
nrow(spain12)
103/1145
nrow(subset(spain05, response == 'atheist'))
nrow(spain05)
115/1146
qnorm(p = 0.975)
(0.0899-0.1003) + 1.96*sqrt(  (0.0899*(1-0899)/1145)    +   (0.1003*(1-0.1003)/1146)  )
(0.0899-0.1003) + 1.96*sqrt(  (0.0899*(1-0.0899)/1145)    +   (0.1003*(1-0.1003)/1146)  )
(0.0899-0.1003) - 1.96*sqrt(  (0.0899*(1-0.0899)/1145)    +   (0.1003*(1-0.1003)/1146)  )
spain12 <- subset(atheism, nationality == 'United States' & year == '2012')
spain05 <- subset(atheism, nationality == 'United States' & year == '2005')
spain12
spain05
spain12 <- subset(atheism, nationality == 'United States' & year == '2012')
spain05 <- subset(atheism, nationality == 'United States' & year == '2005')
spain12
us12 <- subset(atheism, nationality == 'United States' & year == '2012')
us05 <- subset(atheism, nationality == 'United States' & year == '2005')
nrow(us05)
nrow(subset(us05, response == 'atheist'))
nrow(us12)
us12 <- subset(atheism, nationality == 'United States' & year == '2012')
nrow(us12)
nrow(subset(us12, response == 'atheist'))
10/1002
50/1002
(0.0499-0.0099) + 1.96 * sqrt(  (0.0499*(1-0.0499)/1002)    + (0.0099*(1-0.0099)/1002)   )
(0.0499-0.0099) - 1.96 * sqrt(  (0.0499*(1-0.0499)/1002)    + (0.0099*(1-0.0099)/1002)   )
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2*sqrt(p*(1 - p)/n)
plot(me ~ p)
n <- 10
me <- 2*sqrt(0.5*(1 - 0.5)/n)
n <- 10
2*sqrt(0.5*(1 - 0.5)/n)
n <- 100
2*sqrt(0.5*(1 - 0.5)/n)
n <- 9604
2*sqrt(0.5*(1 - 0.5)/n)
n <- 2401
2*sqrt(0.5*(1 - 0.5)/n)
n <- 9602
me <- 2*sqrt(0.5*(1 - 0.5)/n)
n <- 9604
me <- 2*sqrt(0.5*(1 - 0.5)/n)
print(me)
p1 <- 493/1037
n1 <- 1037
p2 <- 596/1028
n2 <- 1028
sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
qnorm(0.975)
qt(0.975, 25)
rm(list = ls())
rm(list=ls())
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
rm(list=ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
x
x[1,]
c(1, 2, 3)
tail(c(1, 2, 3), -1)
tail(c(1, 2, 3), -1)^2
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
print(cost(x, y, theta, lambda))
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
print(cost(x, y, theta, lambda))
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- gradientDescent(x, y, theta, 0.00001, lambda, 40000)
print(cost(x, y, theta, lambda))
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
print(cost(x, y, theta, lambda))
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- gradientDescent(x, y, theta, 0.00001, lambda, 40000)
xxx <- derivativeTheta(x, y, theta, 0.00001, lambda, 40000)
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
lambda <- 1
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
c(1, 2, 3)
head(c(1, 2, 3), 1)
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.00001, 40000, lambda)
plot(xxx)
thetas <- c(
-0.0153449481, -0.0070639670,  0.0008321304, -0.0191927064, -0.0046312015, -0.0138749120, -0.0069733737, -0.0027846139, -0.0031842956,
-0.0086832418, -0.0152071682, -0.0008891625, -0.0049387768, -0.0012545925, -0.0149286649, -0.0076794476, -0.0016728279, -0.0013021809,
-0.0022466947, -0.0017606914, -0.0117813974, -0.0120349499, -0.0004259373, -0.0024456915, -0.0001611890, -0.0028043176, -0.0005610954,
-0.0148608499
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
prediction
realAnswer
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
source('~/github-machine-learning-coursera/exercise2/exercise2_2.R', echo=TRUE)
paste(c(1,2,3))
paste(c(1,2,3), collapse=", ")
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
rm(list=ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
rm(list=ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
plot(xxx)
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
debugSource('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
rm(list=ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
plot(xxx)
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
rm(list=ls())
source('~/github-machine-learning-coursera/exercise2/function-definitions2_2.R')
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.0001, 40000, lambda)
thetas <- c(
0.139347171, -0.049181902,  0.027545597, -0.179664666, -0.042425760, -0.122290551, -0.055800917, -0.024466017, -0.028445530, -0.068515897,
-0.140736585, -0.007143011, -0.046002230, -0.011101567, -0.131053372, -0.065502511, -0.015139026, -0.011279923, -0.020235225, -0.016276692,
-0.099135856, -0.110111228, -0.003108866, -0.022874646, -0.001044644, -0.025793100, -0.004880330, -0.129521318
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
prediction
realAnswer <- (y > 0.5)
realAnswer
prediction
comparison <- prediction == realAnswer
accuracy <- length(comparison[comparison == TRUE]) / length(comparison)
paste('accuracy: ', accuracy)
xxx <- derivativeTheta(x, y, theta, 0.001, 40000, lambda)
setwd('/home/nozes/github-machine-learning-coursera/exercise2')
data <- read.csv2('input/ex2data2.txt', sep = ',' , header = FALSE, stringsAsFactors = FALSE)
plot(data$V1, data$V2, col = data$V3)
# extracting x axis from the dataset
x <- cbind(as.numeric(as.character(data$V1)), as.numeric(as.character(data$V2)))
# appending 1 column (bias)
x <- cbind(rep(1, nrow(x)), x)
# extracting y from the dataset
y <- as.numeric(as.character(data$V3))
length(y)
x <- mapFeature(x)
nrow(x)
length(y)
theta <- rep(0, 28)
lambda <- 1
print(cost(x, y, theta, lambda))
xxx <- derivativeTheta(x, y, theta, 0.001, 40000, lambda)
plot(xxx)
thetas <- c(
0.7591623266,  0.1651206335,  0.5575222611, -1.1288555853, -0.3102956690, -0.6780869999, -0.0750049340, -0.1481843325, -0.1595154354,
-0.1829670580, -0.8360516766, -0.0302620314, -0.2991687160, -0.0801621783, -0.6769467218, -0.2264377630, -0.0965276398, -0.0472310880,
-0.1238599751, -0.1124971507, -0.3952707647, -0.6178207621, -0.0025876233, -0.1481561522,  0.0005497278, -0.1608085625, -0.0366768369,
-0.6265218185
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
prediction
realAnswer
comparison <- prediction == realAnswer
accuracy <- length(comparison[comparison == TRUE]) / length(comparison)
paste('accuracy: ', accuracy)
xxx <- derivativeTheta(x, y, theta, 0.01, 40000, lambda)
plot(xxx)
xxx <- derivativeTheta(x, y, theta, 0.1, 40000, lambda)
thetas <- c(
3.32369487,  0.68000307,  1.43363557, -2.58112513, -0.99772100, -1.73365574,  0.10265785, -0.40901322, -0.43180616, -0.25023332, -1.84293705,
-0.06314165, -0.75558092, -0.27733946, -1.49835058, -0.30655637, -0.23790205, -0.08113157, -0.32052162, -0.32424110, -0.63284333, -1.29792794,
0.02898993, -0.36307882,  0.01400435, -0.39545038, -0.12974736, -1.20434624
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
realAnswer <- (y > 0.5)
comparison <- prediction == realAnswer
accuracy <- length(comparison[comparison == TRUE]) / length(comparison)
paste('accuracy: ', accuracy)
xxx <- derivativeTheta(x, y, theta, 0.1, 40000, lambda)
plot(xxx)
xxx <- derivativeTheta(x, y, theta, 0.05, 40000, lambda)
plot(xxx)
xxx <- derivativeTheta(x, y, theta, 0.01, 40000, lambda)
plot(xxx)
thetas <- c(
1.26972979,  0.62345774,  1.17856297, -2.01710415, -0.90966375, -1.42186773,  0.12297067, -0.36408259, -0.35891353, -0.17438552, -1.45581352,
-0.05613203, -0.61268518, -0.27297076, -1.19016450, -0.24107649, -0.20681524, -0.04834588, -0.27547718, -0.29433032, -0.46105683, -1.04155620,
0.02376462, -0.29160368,  0.01266993, -0.32547776, -0.14281156, -0.92904656
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
realAnswer <- (y > 0.5)
comparison <- prediction == realAnswer
accuracy <- length(comparison[comparison == TRUE]) / length(comparison)
paste('accuracy: ', accuracy)
xxx <- derivativeTheta(x, y, theta, 0.05, 40000, lambda)
thetas <- c(
1.27273951,  0.62527180,  1.18108869, -2.01996086, -0.91742375, -1.43166444,  0.12400635, -0.36553437, -0.35723962, -0.17513048, -1.45815646,
-0.05098906, -0.61555504, -0.27470631, -1.19281652, -0.24218823, -0.20600609, -0.04473075, -0.27778450, -0.29537810, -0.45635749, -1.04320249,
0.02777171, -0.29243131,  0.01556680, -0.32737959, -0.14388693, -0.92465257
)
thetas
prediction <- (hypothesis(thetas, x)[1,] > 0.5)
realAnswer <- (y > 0.5)
comparison <- prediction == realAnswer
accuracy <- length(comparison[comparison == TRUE]) / length(comparison)
paste('accuracy: ', accuracy)
