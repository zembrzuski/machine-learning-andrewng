dim(y)
errorLayer4 <- output - y
errorLayer4
dim(errorLayer4)
errorLayer4 <- t(errorLayer4)
errorLayer4
dim(errorLayer4)
input <- rbind(
c(0, 0),
c(0, 1),
c(1, 0),
c(1, 1)
)
input <- addBiasTherm(input)
dim(input)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
thetasSecondLayer <- rbind(c(10, -20, -20))
outputLayerOne <- hypothesis(input, thetasFirstLayer)
inputLayerTwo <- addBiasTherm(outputLayerOne)
inputLayerTwo
dim(inputLayerTwo)
thetasSecondLayer <- rbind(c(10, -20, -20))
dim(thetasSecondLayer)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim(thetasFirstLayer)
rm(list=ls())
#rm(list = ls())
hypothesis <- function(x, theta) {
z <- x %*% t(theta)
1/(1+exp(-z))
}
addBiasTherm <- function(x) {
cbind(rep(1, nrow(x)), x)
}
cost <- function(x, y, theta) {
m <- nrow(x)
hipo <- hypothesis(x, theta)
vectorCostForEachPoint <- -y*log(hipo) - (1-y)*log(1-hipo)
1/m * sum(vectorCostForEachPoint)
}
input <- rbind(
c(0, 0),
c(0, 1),
c(1, 0),
c(1, 1)
)
input <- addBiasTherm(input)
dim(input)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim(thetasFirstLayer)
thetasSecondLayer <- rbind(c(10, -20, -20))
dim(thetasSecondLayer)
## propagation for the first layer
outputLayerOne <- hypothesis(input, thetasFirstLayer)
## propagation for the second layer
inputLayerTwo <- addBiasTherm(outputLayerOne)
dim(inputLayerTwo)
output <- hypothesis(inputLayerTwo, thetasSecondLayer)
dim(outpu)
dim(output)
rm(list=ls())
source('~/github-machine-learning-coursera/neural-network-recomecando/basefunctions.R')
input <- rbind(
c(0, 0),
c(0, 1),
c(1, 0),
c(1, 1)
)
input <- addBiasTherm(input)
dim(input)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim(thetasFirstLayer)
thetasSecondLayer <- rbind(c(10, -20, -20))
dim(thetasSecondLayer)
## propagation for the first layer
outputLayerOne <- hypothesis(input, thetasFirstLayer)
## propagation for the second layer
inputLayerTwo <- addBiasTherm(outputLayerOne)
dim(input)
dim(inputLayerTwo)
dim(output)
output <- hypothesis(inputLayerTwo, thetasSecondLayer)
dim(output)
rm(list=ls())
input <- rbind(
c(0, 0),
c(0, 1),
c(1, 0),
c(1, 1)
)
input <- addBiasTherm(input)
source('~/github-machine-learning-coursera/neural-network-recomecando/basefunctions.R')
input <- addBiasTherm(input)
dim(input)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim(thetasFirstLayer)
z <- input %*% t(thetasFirstLayer)
dim(z)
source('~/github-machine-learning-coursera/neural-network-recomecando/basefunctions.R')
rm(list=ls())
input <- cbind(
c(0, 0),
c(0, 1),
c(1, 0),
c(1, 1)
)
input
input <- addBiasTherm(input)
source('~/github-machine-learning-coursera/neural-network-recomecando/basefunctions.R')
input <- addBiasTherm(input)
input
dim(input)
thetasFirstLayer <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim
dim(thetasFirstLayer)
theta1 <- rbind(
c(-30, 20, 20),
c(-10, 20, 20)
)
dim(theta1)
theta2 <- rbind(c(10, -20, -20))
dim(theta2)
a1 = x
a2 = hypothesis(a1, theta1)
a1 = x
a2 = hypothesis(a1, theta1)
a1
a1 = x
a1 = input
a1
a2 = hypothesis(a1, theta1)
source('~/github-machine-learning-coursera/neural-network-recomecando/basefunctions.R')
a2 = hypothesis(a1, theta1)
a2 = hypothesis(theta1, a1)
a2
a2 = addBiasTherm(hypothesis(theta1, a1))
dim(a2)
a2
a3 = addBiasTherm(hypothesis(theta2, a2))
a3
a3 = hypothesis(theta2, a2)
a3
a3 > 0.9
y = cbind(c(1, 0, 0, 0))
y
y = rbind(c(1, 0, 0, 0))
y
output = rbind(c(1, 0, 0, 0))
y = output
error3 = a3 - y
error3 = a3 - y
error3
error2 = t(theta2)
t(theta2)
error2 = t(theta2) %*% error3 * (a2 * (1-a2))
error2
theta1
theta1
for(i in 1:nrow(theta1)) {
for(j in 1:ncol(theta1)) {
print(theta[i, j])
}
}
for(i in 1:nrow(theta1)) {
for(j in 1:ncol(theta1)) {
print(theta1[i, j])
}
}
for(i in 1:nrow(theta1)) {
for(j in 1:ncol(theta1)) {
print(a1[,j] * error2[i, ])
}
}
error2
for(i in 1:nrow(theta1)) {
for(j in 1:ncol(theta1)) {
print(a1[,j] * error2[i, ])
}
}
a1[,1]
error2[1,]
a1[1,]
error2[,1]
a1
error2
a1
a[,2]
a1[,2]
error[2,]
error2[2,]
c(4, 5) * c(2, -1)
c(4, 5) * c(2, -1, 0)
a1
error2
a1[,3]
error2[3,]
error2
a2[,1]
error3[1,]
22790/(22790+57737+7003)
1-(22790/(22790+57737+7003))
0.915^2
1-0.12
0.88^4
1-0.88^4
24/112
24/625
100-7
0.93/0.05
0.07/0.05
0.03/0.95
0.97/0.95
0.93*0.05
0.07*0.05
0.03*0.95
0.97*0.95
0.9215+0.0285+0.0035+0.0465
0.0465/(0.0465+0.0285)
24/46
rm(list = ls())
n <- 150 # number of data points
p <- 2 # dimension
sigma <- 1 # variance of the distribution
meanpos <- 0 # centre of the distribution of positive examples
meanneg <- 3 # centre of the distribution of negative examples
npos <- round(n/2) # number of positive examples
nneg <- n-npos # number of negative examples
# Generate the positive and negative examples
xpos <- matrix(rnorm(npos*p,mean=meanpos,sd=sigma),npos,p)
xneg <- matrix(rnorm(nneg*p,mean=meanneg,sd=sigma),npos,p)
x <- rbind(xpos,xneg)
# Generate the labels
y <- matrix(c(rep(1,npos),rep(-1,nneg)))
# Visualize the data
plot(x,col=ifelse(y>0,1,2))
legend("topleft",c(’Positive’,’Negative’),col=seq(2),pch=1,text.col=seq(2))
ntrain <- round(n*0.8) # number of training examples
tindex <- sample(n,ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
plot(x,col=ifelse(y>0,1,2),pch=ifelse(istrain==1,1,2))
ntrain <- round(n*0.8) # number of training examples
tindex <- sample(n,ntrain) # indices of training samples
xtrain <- x[tindex,]
xtest <- x[-tindex,]
ytrain <- y[tindex]
ytest <- y[-tindex]
istrain=rep(0,n)
istrain[tindex]=1
# Visualize
plot(x,col=ifelse(y>0,1,2),pch=ifelse(istrain==1,1,2))
legend("topleft",c(’Positive Train’,’Positive Test’,’Negative Train’,’Negative Test’),
col=c(1,1,2,2),pch=c(1,2,1,2),text.col=c(1,1,2,2))
library(kernlab)
install.packages(kernlab)
library(kernlab)
install.packages('kernlab')
library(kernlab)
library(kernlab)
install.packages('kernlab')
install.packages('kernlab')
install.packages('kernlab')
library(kernlab)
xtrain
ytrain
svp <- ksvm(xtrain, ytrain, type='C-svc', kernel='vanilladot', C=100, scaled=c())
svp
attributes(svp)
alpha(svp)
plot(svp, data=xtrain)
svp
attributes(svp)
alpha(svp)
alphaindex(svp)
b(svp)
svp
attributes(svp)
alpha(svp)
alphaindex(svp)
b(svp)
alpha(svp)
alphaindex(svp)
plot(svp, data=xtrain)
b(svp)
svp
attributes(svp)
alpha(svp)
?alpha
?alpha
?alphaindex
?alphaindex
alphaindex(svp)
rm(list = ls())
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
yMatrix <- createResultMatrix(y)
y[1,]
yMatrix[1,]
yMatrix[501,]
yMatrix[1001,]
yMatrix[2001,]
theta1 <- matrix(data = runif(25*401, max=2) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=2) , nrow = 10, ncol = 26)
rm(list = ls())
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
yMatrix <- createResultMatrix(y)
performForwardPropagation(x, theta1, theta2)
theta1 <- matrix(data = runif(25*401, max=2) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=2) , nrow = 10, ncol = 26)
performForwardPropagation(x, theta1, theta2)
foo <- performForwardPropagation(x, theta1, theta2)
foo[1,]
foo[100,]
foo[10001,]
theta1 <- matrix(data = runif(25*401, max=1) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=1) , nrow = 10, ncol = 26)
foo <- performForwardPropagation(x, theta1, theta2)
foo[1001,]
foo[5001,]
foo[2001,]
foo[2501,]
foo[3001,]
foo[4001,]
theta1 <- matrix(data = runif(25*401, max=1) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=1) , nrow = 10, ncol = 26)
grr <- performForwardPropagation(x, newTheta1, newTheta2)
foo <- performForwardPropagation(x, theta1, theta2)
foo[4001,]
foo[1001,]
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
rm(list = ls())
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
theta1 = read.csv2('input/theta1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
rm(list = ls())
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
theta1 <- matrix(data = runif(25*401, max=1) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=1) , nrow = 10, ncol = 26)
foo <- performForwardPropagation(x, theta1, theta2)
foo[1001,]
foo[3001,]
theta1 <- matrix(data = runif(25*401, max=2) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=2) , nrow = 10, ncol = 26)
grr <- performForwardPropagation(x, newTheta1, newTheta2)
foo <- performForwardPropagation(x, theta1, theta2)
foo[3001,]
foo[1001,]
foo[1,]
foo[305,]
foo[5000,]
alfa <- 0.1
theta1 <- matrix(data = runif(25*401, max=2) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=2) , nrow = 10, ncol = 26)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 100)
alfa <- 0.1
theta1 <- matrix(data = runif(25*401, max=2) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, max=2) , nrow = 10, ncol = 26)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 100)
yMatrix <- createResultMatrix(y)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 100)
newTheta1 <- createMatrixFromTripa(newThetasTripa, ncol(theta1), nrow(theta1), 0)
newTheta2 <- createMatrixFromTripa(newThetasTripa, ncol(theta2), nrow(theta2), length(theta1))
grr <- performForwardPropagation(x, newTheta1, newTheta2)
grr[1,]
grr[10,]
grr[5001,]
grr[5000,]
rm(list = ls())
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
theta1 = read.csv2('input/theta1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
theta2 = read.csv2('input/theta2.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
theta1 <- as.matrix(sapply(theta1, as.numeric))
theta2 <- as.matrix(sapply(theta2, as.numeric))
grr <- performForwardPropagation(x, theta1, theta2)
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
rm(list = ls())
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
theta1 = read.csv2('input/theta1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
theta2 = read.csv2('input/theta2.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
theta1 <- as.matrix(sapply(theta1, as.numeric))
theta2 <- as.matrix(sapply(theta2, as.numeric))
yMatrix <- createResultMatrix(y)
grr <- performForwardPropagation(x, theta1, theta2)
grr[5000,]
grr[10,]
grr[10,] > 0.5
grr[100,] > 0.5
grr[1000,] > 0.5
theta1
rm(list = ls())
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
yMatrix <- createResultMatrix(y)
alfa <- 0.1
theta1 <- matrix(data = runif(25*401, min=-1, max=1) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, min=-1, max=1) , nrow = 10, ncol = 26)
grr <- performForwardPropagation(x, newTheta1, newTheta2)
source('~/github-machine-learning-coursera/neural-network-vai-dar/funcions.R')
rm(list = ls())
source('funcions.R')
rm(list = ls())
source('funcions.R')
setwd('/home/nozes/github-machine-learning-coursera/neural-network-vai-dar')
x = read.csv2('input/data1.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)
x <- as.matrix(sapply(x, as.numeric))
y = read.csv2('input/y.txt', sep=',', stringsAsFactors = FALSE, header = FALSE)$V1
y <- as.matrix(sapply(y, as.numeric))
theta1 <- matrix(data = runif(25*401, min=-1, max=1) , nrow = 25, ncol = 401)
theta2 <- matrix(data = runif(10*26, min=-1, max=1) , nrow = 10, ncol = 26)
grr <- performForwardPropagation(x, theta1, theta2)
grr[1,]
grr[10,]
grr[5000,]
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 50)
yMatrix <- createResultMatrix(y)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 50)
alfa <- 0.1
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 50)
newTheta1 <- createMatrixFromTripa(newThetasTripa, ncol(theta1), nrow(theta1), 0)
newTheta2 <- createMatrixFromTripa(newThetasTripa, ncol(theta2), nrow(theta2), length(theta1))
grr <- performForwardPropagation(x, newTheta1, newTheta2)
grr[5000,]
grr[5000,] > 0.1
grr[5000,] > 0.2
grr[5000,] > 0.5
grr[500,] > 0.5
grr[500,] > 0.1
grr[1,] > 0.1
grr[501,] > 0.1
grr[501,] > 0.5
alfa <- 0.5
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 50)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 100)
newTheta1 <- createMatrixFromTripa(newThetasTripa, ncol(theta1), nrow(theta1), 0)
newTheta2 <- createMatrixFromTripa(newThetasTripa, ncol(theta2), nrow(theta2), length(theta1))
grr <- performForwardPropagation(x, newTheta1, newTheta2)
grr[501,] > 0.5
grr[1,] > 0.5
grr[5000,] > 0.5
grr[5000,] > 0.4
grr[5000,] > 0.1
grr[5000,] > 0.2
grr[501,] > 0.2
grr[501,] > 0.5
grr[1001,] > 0.5
grr[1001,] > 0.4
grr[1001,] > 0.3
grr[1001,] > 0.2
grr[1001,] > 0.1
alfa <- 1
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 50)
newThetasTripa <- gradientDescent(x, yMatrix, theta1, theta2, alfa, 150)
newTheta1 <- createMatrixFromTripa(newThetasTripa, ncol(theta1), nrow(theta1), 0)
newTheta2 <- createMatrixFromTripa(newThetasTripa, ncol(theta2), nrow(theta2), length(theta1))
grr <- performForwardPropagation(x, newTheta1, newTheta2)
grr[1001,] > 0.1
grr[2001,] > 0.1
grr[3001,] > 0.1
grr[3001,] > 0.5
grr[4001,] > 0.5
